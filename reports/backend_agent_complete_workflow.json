{
  "backend_agent_complete_workflow": {
    "created_at": "2025-01-15T23:35:00Z",
    "orchestrator_agent": "Orchestrator Agent",
    "target_agent": "backend_agent",
    "priority_order": [
      "b.21_data_migration_fix",
      "b.20_missing_data_integration",
      "b.19_production_monitoring"
    ],
    "critical_issue": {
      "problem": "Data pipeline broken - 261 statements in flat table, only 1 normalized",
      "root_cause": "ETL writes to flat table but doesn't trigger normalization process",
      "impact": "Missing 260 statements for analytics and reporting",
      "blocking": "All analytics and insights incomplete"
    },
    "csv_data_mapping": {
      "source": "All Response Data - Focus Group - Cleaned.csv",
      "structure": {
        "headers": ["Learner", "Card", "Card type", "Lesson Number", "Global Q#", "PDF Page #", "Response"],
        "card_types": ["Form", "Poll", "Quiz", "Submit media"],
        "data_volume": "423 rows of learner responses"
      },
      "xapi_mapping": {
        "Learner": "actor.account.name → actor_id",
        "Card": "object.definition.name.en-US → activity_id",
        "Card type": "object.definition.interactionType → interaction_type",
        "Response": "result.response → result_response",
        "Context": "context.extensions (lesson_number, global_question_number, pdf_page)"
      },
      "transformation_rules": {
        "actor_id": "lowercase, underscore separated (Audrey Todd → audrey_todd)",
        "activity_id": "card_{number}_{type} (Card 6 (Form) → card_6_form)",
        "verb_mapping": {
          "Form": "completed",
          "Poll": "answered", 
          "Quiz": "answered",
          "Submit media": "completed"
        }
      }
    },
    "implementation_phases": {
      "phase_1_critical": {
        "task": "Complete Data Migration Fix (b.21)",
        "duration": "4 hours",
        "files": [
          "app/migrate_flat_to_normalized.py",
          "app/api/migration.py", 
          "app/etl_streaming.py",
          "app/etl_incremental.py",
          "app/csv_to_xapi_converter.py"
        ],
        "steps": [
          "1. Complete migration script to move 261 statements from flat to normalized",
          "2. Create CSV to xAPI converter using field mapping",
          "3. Update ETL streaming to automatically normalize new statements",
          "4. Create migration API endpoints for monitoring",
          "5. Test everything in production environment"
        ],
        "success_criteria": [
          "All 261 statements successfully migrated to normalized tables",
          "New statements automatically normalized by ETL",
          "CSV data properly converted to xAPI format",
          "Migration API endpoints functional"
        ]
      },
      "phase_2_high": {
        "task": "Missing Data Integration (b.20)",
        "duration": "12 hours", 
        "status": "on_hold",
        "files": [
          "app/api/polls.py",
          "app/api/audio.py",
          "app/api/file_upload.py",
          "app/models/polls.py",
          "app/models/audio.py",
          "app/etl/polls_etl.py",
          "app/etl/audio_etl.py",
          "app/csv_to_xapi_converter.py"
        ],
        "steps": [
          "1. Implement polls data collection from lessons",
          "2. Create audio file upload and processing system",
          "3. Implement audio transcription and analysis",
          "4. Build UI for polls and audio management",
          "5. Integrate with data normalization"
        ],
        "success_criteria": [
          "Polls data collection system functional",
          "Audio file upload and transcription working",
          "UI provides management interface",
          "All data properly normalized for analytics"
        ]
      },
      "phase_3_medium": {
        "task": "Production Monitoring (b.19)",
        "duration": "6 hours",
        "status": "on_hold",
        "description": "Comprehensive production monitoring and alerting system"
      }
    },
    "csv_to_xapi_converter": {
      "file": "app/csv_to_xapi_converter.py",
      "purpose": "Convert CSV data to proper xAPI format using field mapping",
      "functions": [
        "parse_csv_row_to_xapi_statement()",
        "extract_actor_data()", 
        "extract_activity_data()",
        "extract_result_data()",
        "extract_context_data()"
      ],
      "validation_rules": [
        "Learner name must not be empty",
        "Card must match expected pattern",
        "Card type must be one of: Form, Poll, Quiz, Submit media",
        "Response must not be empty"
      ],
      "error_handling": [
        "Missing fields: Log warning and use defaults",
        "Invalid card format: Log error and skip row",
        "Invalid card type: Log error and use 'other'",
        "Empty response: Log warning and use empty string"
      ]
    },
    "data_pipeline_fix": {
      "current_flow": "xAPI → Redis → ETL → statements_flat ❌ (No normalization)",
      "target_flow": "xAPI → Redis → ETL → statements_flat ✅ → Normalization → Normalized Tables",
      "migration_strategy": {
        "step_1": "Migrate existing 261 statements using migrate_flat_to_normalized.py",
        "step_2": "Update ETL streaming to add automatic normalization",
        "step_3": "Update incremental ETL to handle normalization",
        "step_4": "Create migration API for monitoring and triggering"
      }
    },
    "api_endpoints": {
      "migration": [
        "POST /api/migration/run - Trigger migration",
        "GET /api/migration/status - Check migration status", 
        "GET /api/migration/stats - Get migration statistics",
        "GET /api/migration/validate - Validate data integrity"
      ],
      "csv_import": [
        "POST /api/csv/import - Import CSV data",
        "GET /api/csv/status - Check import status",
        "GET /api/csv/validate - Validate CSV format"
      ],
      "polls": [
        "POST /api/polls/ingest - Ingest polls data",
        "GET /api/polls/results - Get poll results",
        "GET /api/polls/analytics - Get poll analytics"
      ],
      "audio": [
        "POST /api/audio/upload - Upload audio file",
        "POST /api/audio/process - Process audio",
        "POST /api/audio/transcribe - Transcribe audio",
        "GET /api/audio/analytics - Get audio analytics"
      ]
    },
    "database_schema": {
      "statements_flat": {
        "purpose": "Raw flattened xAPI statements",
        "current_count": 261,
        "target_count": 261
      },
      "statements_normalized": {
        "purpose": "Normalized statements for analytics",
        "current_count": 1,
        "target_count": 261
      },
      "actors": {
        "purpose": "Unique user/learner data",
        "current_count": 3,
        "target_count": "All unique actors from 261 statements"
      },
      "activities": {
        "purpose": "Unique lesson/course data",
        "current_count": 3, 
        "target_count": "All unique activities from 261 statements"
      },
      "verbs": {
        "purpose": "Unique action types",
        "current_count": 3,
        "target_count": "All unique verbs from 261 statements"
      }
    },
    "testing_requirements": {
      "migration_testing": [
        "Test migration script with sample data",
        "Validate all 261 statements migrated correctly",
        "Test ETL streaming with new normalization",
        "Test migration API endpoints"
      ],
      "csv_import_testing": [
        "Test CSV to xAPI conversion",
        "Validate field mapping accuracy",
        "Test error handling for invalid data",
        "Test with real CSV data"
      ],
      "production_testing": [
        "Test in Heroku production environment",
        "Validate data integrity between flat and normalized",
        "Test performance with large datasets",
        "Verify all API endpoints functional"
      ]
    },
    "success_metrics": {
      "data_migration": [
        "100% of 261 statements migrated to normalized tables",
        "All unique actors, activities, verbs extracted",
        "Data integrity maintained between flat and normalized"
      ],
      "etl_pipeline": [
        "New statements automatically normalized",
        "Incremental ETL handles backfill normalization",
        "Performance maintained with connection pooling"
      ],
      "csv_integration": [
        "CSV data properly converted to xAPI format",
        "Field mapping 100% accurate",
        "Error handling comprehensive and logged"
      ]
    },
    "next_steps": {
      "immediate": "Start with b.21 Data Migration Fix - complete migration script",
      "after_b21": "Resume b.20 Missing Data Integration with CSV mapping",
      "final": "Complete b.19 Production Monitoring",
      "testing": "Post progress to /api/debug/test-report for Testing Agent validation"
    }
  }
}
